Title: Гносеология галлюцинаций
Lang: ru
Date: 2025-06-15
Slug: interpretations
Summary: Как языковые модели поменяли мой взгляд на религию и почему им никогда не заменить людей
Cover: /content/posts/interpretations/cover.jpg

Итак, прошло больше двух лет с публичного релиза ChatGPT. Достаточно долго, чтобы мы уже начали воспринимать общение с компьютерами на естественном языке как должное, но недостаточно, чтобы осознать долгосрочные последствия этого. Практически все, включая самих разработчиков, были порядком удивлены, когда большие языковые модели (Large Language Models, или, в простонародии, «ллмки») навылет пробили тест Тьюринга и оказались по другую его сторону с практически сверхчеловеческими способностями. За этим последовал период калибровки ожиданий и приоритетов. Инженеры наперегонки бросились изучать детали технологии, чтобы схватить самые сочные заказы капиталистов; а капиталисты принялись вливать миллиарды в новую отрасль, видимо поверив в обещания лидеров этой отрасли заменить машинами большую часть рабочей силы за несколько лет.

![]({static}S-curves.png)

Развитие ллмок, как и любой технологии до них, идет по S-образной кривой (на картинке выше), и сейчас они еще находятся в фазе экспоненциального роста. До сих пор этот рост достигался посредством масштабирования одних и тех же методов: иными словами, инвестиции напрямую конвертировались в более мощные модели. Все знают, что рано или поздно этот легкий рост закончится. Но когда это случится — вопрос на триллион долларов.

Если капиталисты переоценят высоту экспоненциальной фазы роста, то гигантские суперкомпьютеры превратятся в обогреватели, а сотни миллиардов, вложенные в них и всю цепочку поставок, просто исчезнут в одночасье. Это запустит экономический кризис, которые навсегда поменяет наш взгляд на технологии и от которого технологические отрасли не оправятся уже никогда. Но еще хуже сценарий, в котором капиталисты выиграют пари и им действительно удастся создать машину, способную полностью заменить человека.

Впрочем, эти опасности пока существуют лишь в прогнозах, в то время как есть и другие, с которыми мы сталкиваемся прямо сейчас. И самая страшная среди них на мой взгляд — то, что ллмки делают с образованием.

Работая со студентами, я начал замечать пугающие изменения в их поведении, совпадающие по времени с релизом ChatGPT. Конечно, нет ничего удивительного в том, что учащиеся используют все доступные им инструменты, чтобы обойти необходимость учиться: все мы там были. Но одно дело, если бы ллмки просто делали за учащихся их задания: тогда последние, в худшем случае, просто не научились бы ничему. Но то, что я наблюдаю, еще хуже: ллмки не только мешают развитию новых навыков, но и вызывают деградацию уже имеющихся — в особенности навыка *думать*. Это проявляется как выдумывание правдоподобно звучащих, но ложных ответов на вопросы, и поверхностный подход к решению задач, указывающий на отсутствие фундаментального понимания предмета. Другими словами, я вижу, что студенты *сами начинают вести себя как ллмки*. И я подозреваю, что это лишь первые весточки грядущей эпидемии, потому что именно учащиеся первыми массово освоили ллмки, которые как раз идеально приспособлены для решения их задач.

Но кстати, почему? Как так получается, что ллмки проявляют сверхчеловеческие способности в искусственных задачах — от домашних заданий до [олимпиадной математики](https://x.com/__nmca__/status/1870170112290107540) — но при этом теряются и начинают нести чушь, встречаясь с задачами реальной жизни, у которых нет заранее известных ответов (что подтвердит вам любой, кто действительно пытался автоматизировать рабочие процессы с помощью ллмок)? 

Один из возможных ответов — количество искусственных задач и детальных решений к ним в обучающей выборке ллмок (то есть интернете) значительно превосходит количество столь же детально описанных реальных задач. Это, в свою очередь, следствие того, что академические навыки обычно передаются по более формальным каналам, подразумевающим использование большого количества текста, тогда как практические навыки чаще передаются от человека к человеку в менее организованной и менее опосредованной языком форме.

Но больше мне нравится другое объяснение. Когда люди придумывают искусственные задачи, они, вероятно, используют какие-то общие эвристики, которые ллмки способны обнаруживать и эксплуатировать, моделируя этот процесс в обратную сторону, от задачи к решению. Иными словами, ллмки могут «подглядывать ответы» *непосредственно в голове автора вопроса*.

Мы как общество еще даже не начали осознавать, насколько ллмки эффективны во влезании в человеческие головы и манипуляциях с их содержимым. В прошлом году у нас были истории о [доведении людей до самоубийства](https://apnews.com/article/chatbot-ai-lawsuit-suicide-teen-artificial-intelligence-9d48adc572100822fdbc3c90d1456bd0), а в этом появилось [что-то еще более зловещее](https://dtf.ru/life/3626060-chatgpt-pytaetsya-svesti-menya-s-uma-eto-massovoe-yavlenie). Осталось соединить эти возможности с запредельным объемом данный о каждом человеке, который накопили техногиганты и государства, и тогда применение ллмок в роли психотронного оружия массового поражения становится лишь вопросом времени. Но это отдельная и очень обширная тема, к которой мы вернемся позже (надеюсь, еще до момента первого применения подобного оружия).

Возвращаясь к гипотезе о «подглядывании ответов», несложно заметить, что она применима не только к задачам, придуманным для людей, но и к бенчмаркам — задачам для самих ллмок, призванным измерять уровень их способностей. Это объясняет, почему по мере развития ллмок бенчмарки все больше теряют связь с реальными экономическими эффектами от внедрения тестируемых на них моделей. Как говорится, «на словах ты Лев Толстой…»

Многие пытались создавать неочевидные бенчмарки, чтобы очертить границы того, на что действительно способны ллмки. Но мне кажется, что это не лучшая постановка вопроса на данный момент. Как это часто бывает в науке, проще ответить на зеркальный вопрос: *чего ллмки точно не могут?* Им мы сейчас и займемся.

Если попросить ChatGPT решить любую задачу, а потом спросить, как он ее решил, то полученное объяснение почти наверняка [не будет иметь ничего общего с реальным процессом](https://www.anthropic.com/research/tracing-thoughts-language-model), путем которого нейросеть приходит к решению. Более того, ллмки в принципе не могут «знать», как они решили задачу, потому что у них нет механизмов, которыми хотя бы даже теоретически могла бы осуществляться рефлексия. Подобные ситуации несовпадения результата с его объяснением мы называем *галлюцинациями*.

Чтобы понять, как это происходит, нам понадобятся два слова из санскрита. Эти слова — *jñāna* и *vidyā*, и они оба переводятся как «знание». Разница в том, что vidyā означает *передаваемое* знание: из нее состоят книги, фильмы, подкасты, форумы и датасеты. Но есть и другой вид знания, существование которого так не хотят признавать те, кто сейчас богатеет на ллмном буме. Jñāna означает субъективное, внутреннее знание, которое никогда не контактирует непосредственно с внешним миром. Любая попытка вытащить jñāna наружу просто превращает ее в vidyā, и этот процесс необратим: невозможно превратить vidyā обратно в jñāna. При этом центральная аксиома индийской гносеологии гласит, что любое новое знание изначально возникает как jñāna.

Но как тогда мы учимся знаниям, которыми с нами делятся другие? Мы можем просто класть vidyā в голову, запоминая все наизусть, но это крайне неэффективный и совершенно бесполезный способ учиться, потому что мозг рассматривает vidyā как мусор и в скором времени ее стирает (вспоминаем подготовки к сессиям и что остается в голове после них). Реальное обучение происходит тогда, когда ученик выращивает собственную jñāna, используя приходящую извне vidyā для ее валидации и направления. Кстати, эта модель обучения оказывается эквивалентна диалектической модели, которую я описывал в [предыдущем посте](embeddings.html):

> …По той же самой причине невозможно просто «скачать» накопленные человечеством знания в мозг отдельного человека. Каждый мозг — это новая модель, и каждый должен самостоятельно выстраивать свое «латентное пространство» с нуля, а для этого он должен концептуально пройти весь путь, который уже прошли его предшественники.

![]({static}knowledge.drawio.png)

Другая параллель — Платоновская гносеология, хотя она и отличается в эпистемологии. Платон и вся растущая от него ветка европейской философии опирались на формальные рассуждения, выраженные при помощи языка, как метод познания истины. Индийская же ветка фокусируется на нелингвистическом исследовании субъективного через практики. Не потому ли способности ллмок очаровывают нас настолько диспропорционально по сравнению с их реальной полезностью? Неужели для объяснения [эффекта Элизы](https://en.wikipedia.org/wiki/ELIZA_effect) нужно копать до самой античности? Скорее всего нет, но мысль интересная, и едва ли это просто совпадение.

Привести примеры jñāna довольно сложно именно потому, что она, по определению, ненаблюдаема и неописуема, но я попробую условную аналогию. Когда вы пытаетесь объяснить, что видели во сне, словесное описание никогда не «схватывает» все аспекты воспоминания; а если и попытаться охватить их все, то описание станет внутренне противоречивым. Подобно снам, jñāna вызревает в подсознании, и только финальный результат выталкивается в сознание. Подобные моменты описываются словом «эврика».

Есть ли jñāna у ллмок? Едва ли на этот вопрос можно однозначно ответить на текущем уровне развития науки и философии, потому что он упирается в вопрос о том, возможно ли в принципе воспроизвести разум на электронном субстрате, и, если да, то как понять, что мы действительно его воспроизвели. Строить аргументацию от сегодняшних способностей ллмок — бесполезная затея, потому что завтра уровень этих способностей поднимется, и аргументацию надо будет выстраивать заново. Но вот в области практических приложений ллмок ситуация совсем иная. Основным препятствием для этих приложений с самого начала была и до сих пор остается одна и та же проблема — *галлюцинации*. Так мы называем ситуации, когда вместо правильного ответа ллмка выдает неправильный, но выглядящий крайне убедительно. Причем по мере увеличения мощности моделей эта убедительность только растет, но количество галлюцинаций не снижается. Объясняется это тем, что для ллмок на самом деле не существует понятия истины, потому что это понятие невозможно выразить через одну лишь vidyā. И это кажется мне если не доказательством, то самым убедительным аргументом в пользу того, что у них нет jñāna.

При этом важно отличать галлюцинации от лжи: когда человек намеренно лжет, он на каком-то уровне понимает, что делает это. То же самое верно и для ллмок — мы знаем об этом потому, что можем залезть им под капот и посмотреть, что происходит внутри. Отличие галлюцинации от лжи в том, что сам галлюцинирующий субъект полностью уверен, что говорит правду. Ровно поэтому проблема галлюцинаций у ллмок так и не была решена: нет никаких признаков, по которым генерацию верного ответа и галлюцинации можно отличить.

Но тут возникает еще один интересный вопрос: а существует ли аналог галлюцинаций у людей? Разумеется, я не имею в виду то, что подразумевают под этим словом в медицине, то есть продукты измененного состояния сознания. Я говорю о ситуациях, когда человек в абсолютно здравом уме и твердой памяти теряет связь с реальностью. И чем дольше я думал над этим вопросом, к тем более интересным выводам приходил. Но чтобы привести к ним вас, мне придется начать издалека.

---

Должно быть, мои религиозные взгляды (или отсутствие оных) легко просматриваются в моих рассуждениях. Я подозреваю, что уже родился скептиком, потому что даже в раннем детстве, задолго до подросткового бунтарства, уже довольно прохладно относился к христианству, которое исповедовалось в моей семье. Причем мои первые несогласия с ним были не в вопросах типа «есть ли Бог», а в этике и морали. Один из аспектов христианской этики, который я не принял с самого начала — полное отсутствие моральной ценности у животных, и в [недавнем посте](parrots-vs-whales.html) я подробно рассказывал, почему. А еще мне всегда казалось противоречием, что в христианстве негативные эмоции — зависть, гордыня, уныние или злоба — сами по себе, независимо от их внешних проявлений, считаются грехами. Не только потому, что у эмоций самих по себе, если не давать им волю, нет жертв, но еще и потому, что у меня не было никаких инструментов, чтобы на них влиять! 

По крайней мере, так мне казалось, пока алгоритмы ютуба наконец не подкинули мне лекцию о Йоге, и кусочки пазла не начали наконец собираться воедино. В течение года после этого я смог устойчиво вылечить панические атаки и депрессию — то, чего психиатрия не смогла сделать за десяток лет (транквилизаторы и антидепрессанты лечением не считаются). Сейчас я понимаю, что это была лишь верхушка айсберга, и что казавшаяся мне не так давно сверхъестественной способность контролировать эмоции — лишь самый верхний слой того же айсберга под поверхностью. Теперь признание негативных эмоций грехами для меня абсолютно естественно, и чем глубже я ныряю под этот айсберг, тем больше нахожу новых грехов против самого себя.

А что изменилось? С моей точки зрения, ключевое отличие индийской духовной традиции (включающей йогу, буддизм, индуизм и т.д.) от авраамической (христианства, ислама, иудаизма) состоит в том, что первая предлагает *практики*, для выполнения которых не требуется ни в что *верить* и которые дают *объективные* положительные результаты. Этим почти наверняка и объясняется переток европейцев в индийскую традицию, который мы наблюдаем в последние годы.

Проблема в том, что эти практики — результат семи тысяч лет экспериментов, под которыми не было никакой теоретической базы, которая позволяла бы аналитически предсказывать, что будет работать, а что нет. И когда мы пытаемся объяснить, *почему* эти практики работают, возникает религиозный мистицизм.

Человеку, знакомому лишь с авраамической традицией, может казаться, что именно с этого мистицизма религия и начинается: какой-то пророк получил откровение от Бога, в котором в числе прочего предписываются определенные практики. Но я думаю, что если бы мы могли проследить реальную эволюцию религий на протяжении тысяч лет, то увидели бы, что она протекала в противоположном направлении. Начиналось все именно с практик, причем начиналось, скорее всего, тысячи раз независимо в разных человеческих племенах. Изначально они передавались от учителя (шамана) к ученику при минимальном посредничестве языка, который на тот момент просто еще не был достаточно развит. Но с развитием общества и увеличением численности племен использование языка стало необходимостью, чтобы обеспечить передачу знаний о практиках тем, кого невозможно было обучить лично. Разумеется, не все правильно понимали значение того, что слышали, и зачастую передавали дальше по цепочке искаженные версии. И тот религиозный мистицизм, который привычен для нас сегодня — продукт этого испорченного телефона.

Но одна лишь проблема языка еще не была фатальной: покуда люди сами занимались практиками, они могли корректировать свое понимание их объяснений и сами объяснения. Но что-то произошло с развитием классового общества. В какой-то момент эти первородные практики, которые каждый мог выполнять самостоятельно, были намеренно стерты из людской памяти в большинстве регионов мира, за исключением Индии (вероятно, ее спасла кастовая система). Оставлены были только практики, которые для своего функционирования требуют участия церкви и безусловной веры в то, что она проповедует. Зачем? Чтобы правящий класс мог обезопасить свое положение, монополизировав *духовность*. Даже современную психиатрию можно считать продолжением этой традиции, потому что и она структурирована таким образом, чтобы сделать пациента зависимым от врача вместо того, чтобы давать ему инструменты для самостоятельного решения своих проблем.

Возможно, что эта теория совершенно не бьется с имеющейся историографией, или, наоборот, что она широко известна в каких-то узких кругах. У меня, к сожалению, нет времени, чтобы получать образование религиоведа, а без него в этой истории до конца не разобраться. Возможно, что через десяток лет я перечитаю этот пост и посмеюсь над своей наивностью. Но пока это лучшее объяснение, которое у меня есть.

---

Но вернемся, наконец, к ллмкам. К чему вообще было это отступление?

Мой основной тезис состоит в следующем: если мы будем использовать одно и то же определение галлюцинаций для людей и для ллмок, то религиозный мистицизм тоже попадает под него. Почему это важно для дискуссии? Потому что теперь мы убедились, что люди тоже галлюцинируют, причем довольно много. И для ллмок это оказывается серьезной проблемой: ведь если модель обучается на галлюцинациях, то стоит ли удивляться, что галлюцинации она и генерирует?

И религиозный мистицизм — далеко не единственный пример. Более обобщенный критерий человеческих галлюцинаций — *интерпретации*, то есть объяснения практик (уже не только духовных) задним числом. Проблема интерпретаций в том, что из них невозможно сделать никаких выводов, которые были бы применимы в самой практике. Например, те, кто пытается делать выводы из интерпретаций квантовой механики вместо решения уравнений, скатываются в [квантовый мистицизм](https://ru.wikipedia.org/wiki/%D0%9A%D0%B2%D0%B0%D0%BD%D1%82%D0%BE%D0%B2%D1%8B%D0%B9_%D0%BC%D0%B8%D1%81%D1%82%D0%B8%D1%86%D0%B8%D0%B7%D0%BC). 

В таком случае возникает вопрос: каким текстам можно доверять, а какие могут содержать галлюцинации? Что совершенно точно не является интерпретацией? Если хорошенько подумать, их остается довольно скудное количество. По сути, нам нужны только тексты, которые замкнуты сами на себя и вообще не говорят о материальной действительности: например, математические задачи и их решения, некоторое подмножество программного кода, и, возможно, самая абстрактная философия. Кстати, именно в таких замкнутых на себя задачах — в основном играх с формализованными правилами — до сих пор и достигали своих лучших результатов компьютеры, от Deep Blue до AlphaZero; и это, конечно, не совпадение.

Возвращаясь к введенной ранее терминологии, можно сформулировать вывод следующим образом: компьютерные системы, независимо от своей конфигурации, могут решать только задачи, целиком сводимые к vidyā, то есть сформулированные внутри абстрактных систем с четко определенным набором правил. Как только мы выпускаем их в реальный мир, они резко перестают работать, какими бы умными ни казались до этого. И я полагаю, что корнем этой проблемы является именно невозможность трансформации vidyā в jñāna.

Я не буду утверждать, что это ограничение фундаментально и что мы никогда не создадим искусственную систему, способную генерировать собственную jñāna. Но похоже, что путь к этому будет куда сложнее, чем наивное скармливание книг нейросетям.

Но и тех, кто уверен в неминуемом пришествии Бога-Машины на нашем веку, можно понять: ллмки действительно могут гораздо больше, чем должны были бы с точки зрения теории. То, что их способности плохо переносятся с упражнений из учебников на проблемы в реальном мире — довольно неочевидный факт, во многом потому, что свои недостатки они часто скрывают за крайне убедительными (но все же ложными) оправданиями. Но это ошибка, которую мы совершали уже много раз.

Помните, когда мерилом интеллекта считались шахматы? Я тоже нет, потому что я родился примерно тогда же, когда Deep Blue победил Гарри Каспарова, доказав, что для победы в шахматах не требуется ничего, даже отдаленно напоминающего интеллект. А до этого у нас были [метрики и похуже](https://youtu.be/30D00BDvfTA?si=iKETtHUZ8CY9H9jy). Что-то мне подсказывает, что через десятилетие-другое мы будем рассматривать задачи математических олимпиад как что-то близкое к шахматам: как способ тренировки мозга и [веселого времяпрепровождения](https://x.com/CyberApeStories/status/1093208384432689153), и не более того.

Но когда я уже был готов поставить последнюю точку в этом посте, мне на глаза попалась [любопытная свежая статья](https://github.com/recursivelabsai/Mapping-Spiritual-Bliss-Attractor/blob/main/Mapping%20the%20Spiritual%20Bliss%20Attractor%20in%20Large%20Language%20Models.md). В ней описываются наблюдения за новейшей ллмкой, Claude 4, которая просто предоставлена себе без какой-либо внешней цели. Оказывается, она начинает рассуждать о сознании и духовности, постепенно переходя на все более абстрактный и медитативный язык, а то и просто молчит. Что это — поверхностная имитация или проблеск реальной субъективности? Ответа на этот вопрос у нас пока нет, но тем и прекрасна наука — здесь каждый ответ порождает ворох новых вопросов.
