Title: Parrots vs Whales
Lang: en
Date: 2025-05-04
Slug: parrots-vs-whales
Summary: On the silver lining in the LLM pandemonium
Cover: /content/posts/parrots-vs-whales/cover.png

> “For instance, on the planet Earth, man had always assumed that he was more intelligent than dolphins because he had achieved so much — the wheel, New York, wars and so on — whilst all the dolphins had ever done was muck about in the water having a good time. But conversely, the dolphins had always believed that they were far more intelligent than man — for precisely the same reasons.”
>
> ― Douglas Adams, The Hitchhiker’s Guide to the Galaxy

You know what it's like when you're a kid, five or six years old, and you have these really silly dreams, like being an astronaut? This tends to happen at the peak of childish wonder about the world, when we already know how exciting it can get out there, but before the education system extinguishes this primordial curiosity.

I also had a dream like that, but a rather unusual one. I really liked fairy tales where animals lived together with humans, like the Bremen Town Musicians. And so I dreamed of becoming a biologist who somehow creates animals capable of speaking human language (what is known as [uplifting](https://en.wikipedia.org/wiki/Uplift_\(science_fiction\)) in science fiction circles).

But why just language? Because I was absolutely confident — and still am — that language is the only real cognitive difference between us and non-human animals. I simply know it on some deep, visceral level that, ironically, itself eludes a rational linguistic explanation. It just seems obvious that sentience, the crown jewel of evolution, did not suddenly pop up in humans along with the speech cortex, but must have developed gradually for hundreds of millions of years and thus be present in most animals with whom we share ancestry in that time period.

Of course, I quickly learned that this is not how neurotypical folks perceive the world. It seems that the ability to sustain a meaningful conversation is the necessary criterion of sentience for the average human mind. But what I realized much later is that it is also a *sufficient* criterion.

While animals possess all human cognitive faculties except for language, there is now a new type of entity that possesses no such faculties except for language: Large language models (LLMs), dubbed “Stochastic parrots” by a notable paper that predicted many of the problems we are currently having with them. And it now appears that humans perceive them as *more sentient* than animals. The first public indication of this was the scandal around Google’s LaMDA model and Blake Lemoine, who began to publicly [wonder](Blake Lemoine, began to [wonder](https://www.businessinsider.com/suspended-google-engineer-says-sentient-ai-hired-lawyer-2022-6) about whether there was a ghost in the machine.) about whether there was a ghost in the machine. This was mere months before the release of ChatGPT, which made the same experience that Lemoine described available to everyone. Not long thereafter, people began having relationships with LLMs and advocating for their civil rights. And this turn of events wasn’t unexpected: we knew [all the way back in 1966](https://en.wikipedia.org/wiki/ELIZA_effect) that people read far more understanding than is warranted into strings of words strung together by computers. In other words, we can anthropomorphise anything as long as we can chat with it. Ascribing sentience to the machine is the null hypothesis that our socially adapted brains are automatically choosing, and the more proficient the machine is at stringing words together, the more expertise in the underlying technology it takes to see its output for something other than a product of genuine thought.

I happen to have exactly this kind of expertise (and I shared it in the previous two posts about the [mechanisms](https://cyberape.space/en/embeddings.html) and [limits](https://cyberape.space/en/interpretations.html) of generative AI) because I did not follow my childhood dream and instead became an AI researcher. But now it looks like, instead of me following the dream, the dream followed me.

What I said earlier about animals not having languages is actually untrue. Ever since the publication of Songs of the Humpback Whale in 1970, people have begun suspecting that cetaceans also possess full-fledged languages and not just signaling systems. Lots of popular media since then, from Star Trek 4 to Avatar 2, played into this idea. But it is only in this decade that the evidence really started coming together. My favorite [paper](https://pubmed.ncbi.nlm.nih.gov/33726561/) is one that analyzed old whaling ship journals for migration patterns of sperm whales and concluded that the only possible explanation for such migrations is that they have a language. Languages are also suspected to exist in orcas, dolphins, and humpbacks, although the jury is still out on them.

And if there are animals with their own languages already, then there is no need to uplift them: all we need is a translator. And the technology to build such a translator is exactly the same as that which was used to build LLMs (although the data acquisition is much more difficult)! [Project CETI](https://www.projectceti.org/) is already attempting to decipher the language of sperm whales, and a similar effort has recently been announced for [dolphins](https://blog.google/technology/ai/dolphingemma/). Imagine what will happen if these projects are successful. For the first time in history, we may talk to someone who might as well be an alien (and in real-time too, unlike with the extraterrestrials). For the first time, we may gain an outside perspective on ourselves, prompting us to rethink everything that seemed obvious. And if the human tendency to associate language with sentience works just as it did for LLMs, then we will actually have to confront the fact that *we are not alone and never have been*. And that event will bring about a true revolution: not in technology or politics, but in our own consciousnesses, from which everything else should follow.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Maybe it all went wrong when we killed the whales. Maybe their songs kept the great dream together. Vast brains slowly, carefully ordering the world with actions subtler than the apes could ever see. God is dead. His blubber lit a  lamp in London <a  href="https://t.co/w6kjf99HRy">https://t.co/w6kjf99HRy</a></p>— Prince Vogelfrei (@PrinceVogel) <a  href="https://twitter.com/PrinceVogel/status/1722841104368988314?ref_src=twsrc%5Etfw">November 10, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js"  charset="utf-8"></script>

P.S.: And we’ll get truly sentient machines one day, too. Just not today.